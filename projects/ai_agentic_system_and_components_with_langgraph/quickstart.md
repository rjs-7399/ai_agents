# AI Agent with Langgraph Framework Capabilities

## These are the phases

- Simple AI Agent
- Working With Chain
- Routing
- Agent with Memory
- States
- Filters and Reducers
- State Management
- Breakpoints
- Human in the loop
- Long term memory management

## Steps:

- Components of Graph.
- Langgraph is a framework wrapper on langchain.
- Langgraph has three main components: nodes, edges, state.
- Node is just a vertex representing python function or module to be executed.
- Here edge is a directional path between two nodes.
- We have normal edge and conditional edge.
- Normal edge means, the edge that needs to be traversed each time we run it.
- The conditional edge will be traversed when the condition is satisfied.
- An orphan node (sometimes called an isolated node) in graph theory is a node/vertex that has no edges connecting it to any other nodes in the graph.
- In other words, it's a completely disconnected vertex with 0 degree of Origin.
- State is a building block of graph.
- Graphs also have the ability to keep track of what is going on in the graph generally.
- This is where state comes in the picture.
- State is basically the object that we pass between different nodes and edges of our graph.
- This object holds information that is used to communicate between the different nodes and edges.
- It serves as the input/output schema for all nodes and edges.
- Step 1: Building A Simple AI Agent
  - Building Graph State
  - Building Nodes Functions
  - Building Graph Nodes
  - Building Edges
- Graph Invocation Notes
- Compiled graphs implement the runnable protocol in Langchain. This allows us to work with graphs just like any other chain in LangChain.
- To invoke the graph we need to pass in the state.
- Each node will receive the current state and overrides it.
- Execution continues till we terminate, basically till we reach the END node.
- invoke runs the graph asynchronously, waiting on each node to complete before moving to the next node.
- The final state of the graph after being overridden by all the nodes get returned.
- Step 2: Working with Chain
- A chat message represents different type of conversations on exchanges in langchain.
- What we type is a HumanMessage, what AI types is AIMessage.
- We have SystemMessage, HumanMessage, AIMessage, Multimodality
- SystemMessage - for content which should be passed to direct conversation.
- HumanMessage - for content in the input from the user.
- AIMessage - for content in the response from model.
- Multimodality - for more information on multimodal content.
- Chat Model: It is the llm that is fine tune to be able to have chat conversation.
- Tools: Provides capability to llm to interact with an external world.
- Here from the simple graph we saw that we traversed node 1, so at node 1 the message state become node 1. At node 2 message state become node 2. At node 3 message state become node 3.
- So at the time of traversing new node the message state will get changed pointing to that particular node.
- So it won't keep track of older things that happened.
- Everytime the values are getting overwritten on each node.
- This is not effective as agent doesn't know anything from previous experience.
- So here the concept of memory comes in.
- Here we can add the reducer.
- Here if we add a new approach in which at the time of traversing any new node the information from that perticular node will get appended to the state.
- In this way the agent will have all the information about each node.
- But here the LLM has one limitation called context window limit. That means LLM can store upto a fixed limit of things. Not more than that.
- Step 3: Building Routing Logic
- We have an AI Agent, which has a couple of abilities, with some paths. 
- We have one main logic that recieves user's query and based on the user's query the agent is able to decide which path to take, which components to use. Which nodes to go to depending on the user's input.
- Here the routing logic comes in the picture.
- The chat model (our intelligent worker) that decides whether a tool is needed or not.
- A special node called ToolNode that knows how to use different tools when needed.
- A smart routing system that looks at each response and decides: "Does this need a tool ? If yes, let's use the tool and then continue the conversation"
- "No tool needed ? Then let's wrap up the request."
- 